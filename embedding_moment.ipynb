{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9236665-5642-4478-8b6a-415250a22c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install momentfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6203b3d8-55e1-428c-b589-3eb32783f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative\n",
    "!pip install git+https://github.com/moment-timeseries-foundation-model/moment.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f532561-b2a4-4b63-8445-f9a89b4b06dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy pandas scikit-learn matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9536921-c901-4d79-9992-8217bf745ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py311/lib/python3.11/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# getting the MOMENT model \n",
    "from momentfm import MOMENTPipeline\n",
    "\n",
    "model = MOMENTPipeline.from_pretrained(\n",
    "    \"AutonLab/MOMENT-1-large\", \n",
    "    model_kwargs={'task_name': 'embedding'}, # We are loading the model in `embedding` mode to learn representations\n",
    "    local_files_only=True,  # Whether or not to only look at local files (i.e., do not try to download the model).\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c22aefb9-6c8a-4a7a-8b75-130b86302ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOMENTPipeline(\n",
      "  (normalizer): RevIN()\n",
      "  (tokenizer): Patching()\n",
      "  (patch_embedding): PatchEmbedding(\n",
      "    (value_embedding): Linear(in_features=8, out_features=1024, bias=False)\n",
      "    (position_embedding): PositionalEmbedding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 1024)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 16)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-23): 23 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (head): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py311/lib/python3.11/site-packages/momentfm/models/moment.py:174: UserWarning: Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\n",
      "  warnings.warn(\"Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\")\n"
     ]
    }
   ],
   "source": [
    "model.init()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2323f89c-9e69-462c-8bcc-5f8fcf4852cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 341231104\n"
     ]
    }
   ],
   "source": [
    "# Number of parameters in the encoder\n",
    "num_params = sum(p.numel() for p in model.encoder.parameters())\n",
    "print(f\"Number of parameters: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "240327ce-1f32-481b-a6b0-856184f4a9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqn</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>education</th>\n",
       "      <th>married</th>\n",
       "      <th>pir</th>\n",
       "      <th>bmi</th>\n",
       "      <th>time1</th>\n",
       "      <th>time2</th>\n",
       "      <th>...</th>\n",
       "      <th>time2007</th>\n",
       "      <th>time2008</th>\n",
       "      <th>time2009</th>\n",
       "      <th>time2010</th>\n",
       "      <th>time2011</th>\n",
       "      <th>time2012</th>\n",
       "      <th>time2013</th>\n",
       "      <th>time2014</th>\n",
       "      <th>time2015</th>\n",
       "      <th>time2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21009</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.79</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21010</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21012</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 2024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    seqn  gender  age  race  education  married   pir  bmi  time1  time2  ...  \\\n",
       "1  21009       1   55     3          3        1  3.79    1      0      0  ...   \n",
       "2  21010       2   52     3          4        6  1.24    1      0      0  ...   \n",
       "3  21012       1   63     4          3        6  0.89    0      1      0  ...   \n",
       "\n",
       "   time2007  time2008  time2009  time2010  time2011  time2012  time2013  \\\n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         1         1         0         0         0         1         1   \n",
       "\n",
       "   time2014  time2015  time2016  \n",
       "1         0         0         0  \n",
       "2         0         0         0  \n",
       "3         0         0         0  \n",
       "\n",
       "[3 rows x 2024 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import NHANES data \n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/data_wide.csv\", index_col=0)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df652978-d693-4987-a712-3d84efb0b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the data with L2 normalization \n",
    "import numpy as np\n",
    "\n",
    "def normalize_l2(x):\n",
    "    x = np.array(x)\n",
    "    if x.ndim == 1:\n",
    "        norm = np.linalg.norm(x)\n",
    "        if norm < 1e-10:  # Use a small threshold instead of exact zero\n",
    "            return x\n",
    "        return x / norm\n",
    "    else:\n",
    "        # Create a copy of x to store the result\n",
    "        normalized = np.zeros_like(x, dtype=np.float64)\n",
    "        \n",
    "        # Calculate norms for each row\n",
    "        norms = np.linalg.norm(x, 2, axis=1, keepdims=True)\n",
    "        \n",
    "        # Process each row separately, avoiding division by zero\n",
    "        for i in range(x.shape[0]):\n",
    "            if norms[i] >= 1e-10:  # Only normalize if norm is not effectively zero\n",
    "                normalized[i] = x[i] / norms[i]\n",
    "            else:\n",
    "                normalized[i] = x[i]  # Keep original values if norm is effectively zero\n",
    "                \n",
    "        return normalized\n",
    "\n",
    "def prepare_data_from_df(df, value_columns, n_channels=1):\n",
    "    MAX_SEQ_LEN = 512\n",
    "    \n",
    "    # convert time series columns to numpy array\n",
    "    data = df[value_columns].values\n",
    "    n_batchsize, n_context = data.shape\n",
    "    print(f\"Original data shape: {data.shape}\")\n",
    "    \n",
    "    # confirm the reshaping\n",
    "    context_per_channel = n_context // n_channels\n",
    "    if n_context % n_channels != 0:\n",
    "        raise ValueError(f\"Number of features ({n_context}) must be divisible by number of channels ({n_channels})\")\n",
    "    \n",
    "    # check if sequence length is greater than max=512 and truncate if needed.\n",
    "    if context_per_channel > MAX_SEQ_LEN:\n",
    "        print(f\"Warning: Context length per channel ({context_per_channel}) exceeds maximum of {MAX_SEQ_LEN}. \"\n",
    "              f\"Truncating to {MAX_SEQ_LEN}.\")\n",
    "        new_n_context = n_channels * MAX_SEQ_LEN\n",
    "        data = data[:, :new_n_context]\n",
    "        context_per_channel = MAX_SEQ_LEN\n",
    "    \n",
    "    # Apply L2 normalization to the data\n",
    "    data = normalize_l2(data)\n",
    "    \n",
    "    # reshape the data into [batchsize, channel, context]\n",
    "    data_reshaped = data.reshape(n_batchsize, n_channels, context_per_channel)\n",
    "    print(f\"Reshaped data shape: {data_reshaped.shape}\")\n",
    "    \n",
    "    # Convert to torch tensor\n",
    "    data_tensor = torch.FloatTensor(data_reshaped)\n",
    "    print(f\"Tensor shape: {data_tensor.shape}\")\n",
    "    \n",
    "    return data_tensor  # [batchsize, channel, context_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce289305-94f2-4ce7-a492-95e87948ea53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (6943, 2016)\n",
      "Warning: Context length per channel (2016) exceeds maximum of 512. Truncating to 512.\n",
      "Reshaped data shape: (6943, 1, 512)\n",
      "Tensor shape: torch.Size([6943, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "value_columns = [col for col in df.columns if col.startswith('time')]\n",
    "data_tensor = prepare_data_from_df(df, value_columns, n_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dbd92b-a439-497c-85aa-f625b602f04f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### DONT RUN. embedding of the data \n",
    "from pprint import pprint\n",
    "\n",
    "output = model(x_enc=data_tens or)\n",
    "pprint(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46836729-69f6-47f0-9134-710c390fa61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### DONT RUN: get 3500 random subset from the data_tensor\n",
    "import random\n",
    "\n",
    "np.random.seed(1)\n",
    "random_indices = random.sample(range(data_tensor.shape[0]), 3500)\n",
    "subset_data = data_tensor[random_indices]\n",
    "\n",
    "print(f\"Subset shape: {subset_data.shape}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fabe4140-e36c-423b-aaf3-ebe493cc3f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset shape: torch.Size([3500, 1, 512])\n",
      "Subset shape: torch.Size([3443, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "# get two chunks of subset \n",
    "\n",
    "subset_data1 = data_tensor[:3500]\n",
    "subset_data2 = data_tensor[3500:]\n",
    "\n",
    "print(f\"Subset shape: {subset_data1.shape}\")\n",
    "print(f\"Subset shape: {subset_data2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20bfcd70-eaa5-4c46-a76a-b6a8023aec65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeseriesOutputs(forecast=None,\n",
      "                  anomaly_scores=None,\n",
      "                  logits=None,\n",
      "                  labels=None,\n",
      "                  input_mask=tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]]),\n",
      "                  pretrain_mask=None,\n",
      "                  reconstruction=None,\n",
      "                  embeddings=tensor([[-0.0620,  0.0345, -0.0244,  ..., -0.0308,  0.0389, -0.0119],\n",
      "        [-0.0112,  0.0668, -0.0565,  ..., -0.0841,  0.0629,  0.0299],\n",
      "        [-0.0395,  0.0285, -0.0204,  ..., -0.0179,  0.0298,  0.0084],\n",
      "        ...,\n",
      "        [-0.0043,  0.0217, -0.0580,  ..., -0.0625,  0.0413,  0.0014],\n",
      "        [-0.0472,  0.0492, -0.0517,  ..., -0.0936,  0.0623,  0.0065],\n",
      "        [-0.0479,  0.0030, -0.0557,  ..., -0.0223,  0.0237, -0.0294]]),\n",
      "                  metadata='mean',\n",
      "                  illegal_output=False)\n"
     ]
    }
   ],
   "source": [
    "# embedding of the subset1\n",
    "from pprint import pprint\n",
    "\n",
    "output1 = model(x_enc=subset_data1)\n",
    "pprint(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6e3e7f0-8942-480c-b1dc-f8526e69a6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqn</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>education</th>\n",
       "      <th>married</th>\n",
       "      <th>pir</th>\n",
       "      <th>bmi</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21009</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.79</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.061991</td>\n",
       "      <td>0.034499</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010907</td>\n",
       "      <td>0.012167</td>\n",
       "      <td>-0.044770</td>\n",
       "      <td>-0.005853</td>\n",
       "      <td>-0.007444</td>\n",
       "      <td>-0.006063</td>\n",
       "      <td>-0.012152</td>\n",
       "      <td>-0.030841</td>\n",
       "      <td>0.038901</td>\n",
       "      <td>-0.011916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21010</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.011184</td>\n",
       "      <td>0.066814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049296</td>\n",
       "      <td>0.011262</td>\n",
       "      <td>-0.027850</td>\n",
       "      <td>0.024789</td>\n",
       "      <td>-0.005914</td>\n",
       "      <td>-0.013952</td>\n",
       "      <td>-0.045955</td>\n",
       "      <td>-0.084095</td>\n",
       "      <td>0.062894</td>\n",
       "      <td>0.029902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21012</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.039453</td>\n",
       "      <td>0.028493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003310</td>\n",
       "      <td>0.027176</td>\n",
       "      <td>-0.055294</td>\n",
       "      <td>0.011044</td>\n",
       "      <td>-0.029307</td>\n",
       "      <td>0.011807</td>\n",
       "      <td>-0.034652</td>\n",
       "      <td>-0.017947</td>\n",
       "      <td>0.029808</td>\n",
       "      <td>0.008437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21015</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.048768</td>\n",
       "      <td>0.024437</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046362</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>-0.038224</td>\n",
       "      <td>-0.028987</td>\n",
       "      <td>-0.015003</td>\n",
       "      <td>0.025050</td>\n",
       "      <td>-0.025461</td>\n",
       "      <td>-0.002104</td>\n",
       "      <td>0.051183</td>\n",
       "      <td>-0.042558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21017</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.060303</td>\n",
       "      <td>0.028413</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066772</td>\n",
       "      <td>0.010558</td>\n",
       "      <td>-0.019813</td>\n",
       "      <td>0.014503</td>\n",
       "      <td>-0.047679</td>\n",
       "      <td>0.018136</td>\n",
       "      <td>-0.029235</td>\n",
       "      <td>-0.060501</td>\n",
       "      <td>0.060125</td>\n",
       "      <td>-0.018740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1032 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    seqn  gender  age  race  education  married   pir  bmi         0  \\\n",
       "1  21009       1   55     3          3        1  3.79    1 -0.061991   \n",
       "2  21010       2   52     3          4        6  1.24    1 -0.011184   \n",
       "3  21012       1   63     4          3        6  0.89    0 -0.039453   \n",
       "4  21015       1   83     3          4        1  1.20    1 -0.048768   \n",
       "5  21017       2   37     1          2        6  0.21    0 -0.060303   \n",
       "\n",
       "          1  ...      1014      1015      1016      1017      1018      1019  \\\n",
       "1  0.034499  ... -0.010907  0.012167 -0.044770 -0.005853 -0.007444 -0.006063   \n",
       "2  0.066814  ... -0.049296  0.011262 -0.027850  0.024789 -0.005914 -0.013952   \n",
       "3  0.028493  ...  0.003310  0.027176 -0.055294  0.011044 -0.029307  0.011807   \n",
       "4  0.024437  ... -0.046362  0.007679 -0.038224 -0.028987 -0.015003  0.025050   \n",
       "5  0.028413  ... -0.066772  0.010558 -0.019813  0.014503 -0.047679  0.018136   \n",
       "\n",
       "       1020      1021      1022      1023  \n",
       "1 -0.012152 -0.030841  0.038901 -0.011916  \n",
       "2 -0.045955 -0.084095  0.062894  0.029902  \n",
       "3 -0.034652 -0.017947  0.029808  0.008437  \n",
       "4 -0.025461 -0.002104  0.051183 -0.042558  \n",
       "5 -0.029235 -0.060501  0.060125 -0.018740  \n",
       "\n",
       "[5 rows x 1032 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract embedding results \n",
    "embeddings1 = output1.embeddings\n",
    "embeddings1_np = embeddings1.detach().cpu().numpy()\n",
    " \n",
    "# convert to dataframe \n",
    "embeddings1_df = pd.DataFrame(embeddings1_np)\n",
    "\n",
    "# combine with columns up to 'bmi' from the original dataset \n",
    "df_subset1 = df.iloc[:3500].reset_index(drop=True)\n",
    "embeddings1_df = pd.concat([pd.DataFrame(embeddings1_np), df_subset1.loc[:, :'bmi']], axis=1)\n",
    "\n",
    "# reorder columns \n",
    "original_cols1 = df_subset1.loc[:, :'bmi'].columns.tolist()\n",
    "embeddings1_cols = list(range(embeddings1_np.shape[1])) \n",
    "embeddings1_df = embeddings1_df[original_cols1 + embeddings1_cols]\n",
    "\n",
    "embeddings1_df.index = range(1, len(embeddings1_df) + 1)\n",
    "\n",
    "embeddings1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a35f103a-1c51-4ac8-a3b0-baeb89f58d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save embeddings\n",
    "embeddings1_df.to_csv(\"./data/embeddings_moment_subset1_1024.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63a94c6d-0b4b-485c-b609-3728d83bbfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqn</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>education</th>\n",
       "      <th>married</th>\n",
       "      <th>pir</th>\n",
       "      <th>bmi</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21009</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.79</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.061991</td>\n",
       "      <td>0.034499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035495</td>\n",
       "      <td>0.031233</td>\n",
       "      <td>-0.023033</td>\n",
       "      <td>0.005586</td>\n",
       "      <td>-0.031550</td>\n",
       "      <td>-0.886460</td>\n",
       "      <td>-0.090072</td>\n",
       "      <td>-0.123459</td>\n",
       "      <td>-0.012563</td>\n",
       "      <td>-0.026847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21010</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.011184</td>\n",
       "      <td>0.066814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020015</td>\n",
       "      <td>0.019269</td>\n",
       "      <td>-0.023844</td>\n",
       "      <td>-0.032517</td>\n",
       "      <td>-0.097130</td>\n",
       "      <td>-0.933672</td>\n",
       "      <td>-0.072217</td>\n",
       "      <td>-0.092843</td>\n",
       "      <td>0.016826</td>\n",
       "      <td>-0.035561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21012</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.039453</td>\n",
       "      <td>0.028493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008160</td>\n",
       "      <td>-0.001205</td>\n",
       "      <td>-0.002655</td>\n",
       "      <td>0.012329</td>\n",
       "      <td>-0.039374</td>\n",
       "      <td>-0.845930</td>\n",
       "      <td>-0.082718</td>\n",
       "      <td>-0.155851</td>\n",
       "      <td>-0.012679</td>\n",
       "      <td>-0.024948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21015</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.048768</td>\n",
       "      <td>0.024437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>0.048301</td>\n",
       "      <td>-0.027509</td>\n",
       "      <td>0.008435</td>\n",
       "      <td>-0.053612</td>\n",
       "      <td>-0.812731</td>\n",
       "      <td>-0.075590</td>\n",
       "      <td>-0.156991</td>\n",
       "      <td>-0.025177</td>\n",
       "      <td>-0.040843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21017</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.060303</td>\n",
       "      <td>0.028413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017056</td>\n",
       "      <td>0.039506</td>\n",
       "      <td>-0.017053</td>\n",
       "      <td>0.012682</td>\n",
       "      <td>-0.067095</td>\n",
       "      <td>-0.816805</td>\n",
       "      <td>-0.047673</td>\n",
       "      <td>-0.140296</td>\n",
       "      <td>0.005803</td>\n",
       "      <td>-0.025212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    seqn  gender  age  race  education  married   pir  bmi         0  \\\n",
       "1  21009       1   55     3          3        1  3.79    1 -0.061991   \n",
       "2  21010       2   52     3          4        6  1.24    1 -0.011184   \n",
       "3  21012       1   63     4          3        6  0.89    0 -0.039453   \n",
       "4  21015       1   83     3          4        1  1.20    1 -0.048768   \n",
       "5  21017       2   37     1          2        6  0.21    0 -0.060303   \n",
       "\n",
       "          1  ...        40        41        42        43        44        45  \\\n",
       "1  0.034499  ...  0.035495  0.031233 -0.023033  0.005586 -0.031550 -0.886460   \n",
       "2  0.066814  ... -0.020015  0.019269 -0.023844 -0.032517 -0.097130 -0.933672   \n",
       "3  0.028493  ...  0.008160 -0.001205 -0.002655  0.012329 -0.039374 -0.845930   \n",
       "4  0.024437  ...  0.008419  0.048301 -0.027509  0.008435 -0.053612 -0.812731   \n",
       "5  0.028413  ...  0.017056  0.039506 -0.017053  0.012682 -0.067095 -0.816805   \n",
       "\n",
       "         46        47        48        49  \n",
       "1 -0.090072 -0.123459 -0.012563 -0.026847  \n",
       "2 -0.072217 -0.092843  0.016826 -0.035561  \n",
       "3 -0.082718 -0.155851 -0.012679 -0.024948  \n",
       "4 -0.075590 -0.156991 -0.025177 -0.040843  \n",
       "5 -0.047673 -0.140296  0.005803 -0.025212  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reducing dimension \n",
    "def reduce_dimension(embedding, dim=50):\n",
    "    return embedding[:, :dim]\n",
    "reduced_embeddings1_np = reduce_dimension(embeddings1_np)\n",
    "\n",
    "# convert to dataframe \n",
    "red_embeddings1_df = pd.DataFrame(reduced_embeddings1_np)\n",
    "red_embeddings1_df = pd.concat([pd.DataFrame(reduced_embeddings1_np), df_subset1.loc[:, :'bmi']], axis=1)\n",
    "\n",
    "original1_cols = df_subset1.loc[:, :'bmi'].columns.tolist()\n",
    "embedding1_cols = list(range(reduced_embeddings1_np.shape[1])) \n",
    "red_embeddings1_df = red_embeddings1_df[original1_cols + embedding1_cols]\n",
    "red_embeddings1_df.index = range(1, len(red_embeddings1_df) + 1)\n",
    "\n",
    "red_embeddings1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a1ea512-d6e7-404b-9cf4-7a6998a7b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save embeddings with dimension reduction \n",
    "red_embeddings1_df.to_csv(\"./data/embeddings_moment_subset1_50.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63d822d-2540-42c2-bdeb-8a143badfbbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7d1936b-cf8f-44cb-94d1-7c48c427a512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeseriesOutputs(forecast=None,\n",
      "                  anomaly_scores=None,\n",
      "                  logits=None,\n",
      "                  labels=None,\n",
      "                  input_mask=tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]]),\n",
      "                  pretrain_mask=None,\n",
      "                  reconstruction=None,\n",
      "                  embeddings=tensor([[-0.0550,  0.0400, -0.0481,  ..., -0.0404,  0.0455, -0.0380],\n",
      "        [-0.0359,  0.0193, -0.0406,  ..., -0.0862,  0.0713, -0.0002],\n",
      "        [-0.0250,  0.0239, -0.0192,  ..., -0.0529,  0.0415, -0.0261],\n",
      "        ...,\n",
      "        [-0.0615, -0.0107, -0.0376,  ..., -0.0081,  0.0572, -0.0397],\n",
      "        [-0.0341,  0.0167, -0.0480,  ..., -0.0439,  0.0328, -0.0374],\n",
      "        [-0.0525,  0.0176, -0.0418,  ..., -0.0206,  0.0385,  0.0292]]),\n",
      "                  metadata='mean',\n",
      "                  illegal_output=False)\n"
     ]
    }
   ],
   "source": [
    "# embedding of the subset2\n",
    "from pprint import pprint\n",
    "\n",
    "output2 = model(x_enc=subset_data2)\n",
    "pprint(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "044ec1b8-e7eb-451b-9b27-cc7e0d5f4228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqn</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>education</th>\n",
       "      <th>married</th>\n",
       "      <th>pir</th>\n",
       "      <th>bmi</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31183</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.055011</td>\n",
       "      <td>0.039953</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074217</td>\n",
       "      <td>-0.022236</td>\n",
       "      <td>-0.036040</td>\n",
       "      <td>0.023753</td>\n",
       "      <td>0.007128</td>\n",
       "      <td>-0.036365</td>\n",
       "      <td>-0.013751</td>\n",
       "      <td>-0.040431</td>\n",
       "      <td>0.045520</td>\n",
       "      <td>-0.037951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31186</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.035945</td>\n",
       "      <td>0.019263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030063</td>\n",
       "      <td>0.008317</td>\n",
       "      <td>-0.045595</td>\n",
       "      <td>-0.010246</td>\n",
       "      <td>-0.030636</td>\n",
       "      <td>-0.023607</td>\n",
       "      <td>-0.031996</td>\n",
       "      <td>-0.086167</td>\n",
       "      <td>0.071279</td>\n",
       "      <td>-0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31187</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4.29</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.024960</td>\n",
       "      <td>0.023898</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032067</td>\n",
       "      <td>0.013064</td>\n",
       "      <td>-0.036885</td>\n",
       "      <td>-0.004430</td>\n",
       "      <td>-0.022011</td>\n",
       "      <td>-0.014765</td>\n",
       "      <td>-0.031623</td>\n",
       "      <td>-0.052872</td>\n",
       "      <td>0.041466</td>\n",
       "      <td>-0.026117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31194</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.039385</td>\n",
       "      <td>0.047492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036413</td>\n",
       "      <td>0.025165</td>\n",
       "      <td>-0.063565</td>\n",
       "      <td>0.029113</td>\n",
       "      <td>-0.045179</td>\n",
       "      <td>-0.027492</td>\n",
       "      <td>-0.020567</td>\n",
       "      <td>-0.053423</td>\n",
       "      <td>0.059044</td>\n",
       "      <td>0.000596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31195</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.046546</td>\n",
       "      <td>0.026695</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031783</td>\n",
       "      <td>0.011810</td>\n",
       "      <td>-0.052689</td>\n",
       "      <td>-0.017665</td>\n",
       "      <td>-0.020827</td>\n",
       "      <td>-0.023144</td>\n",
       "      <td>-0.007389</td>\n",
       "      <td>-0.059902</td>\n",
       "      <td>0.054974</td>\n",
       "      <td>-0.015622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1032 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    seqn  gender  age  race  education  married   pir  bmi         0  \\\n",
       "1  31183       2   33     3          5        1  3.90    1 -0.055011   \n",
       "2  31186       2   46     1          1        3  1.68    1 -0.035945   \n",
       "3  31187       2   22     3          4        6  4.29    1 -0.024960   \n",
       "4  31194       2   47     1          1        3  1.02    1 -0.039385   \n",
       "5  31195       1   73     3          4        1  5.00    0 -0.046546   \n",
       "\n",
       "          1  ...      1014      1015      1016      1017      1018      1019  \\\n",
       "1  0.039953  ... -0.074217 -0.022236 -0.036040  0.023753  0.007128 -0.036365   \n",
       "2  0.019263  ... -0.030063  0.008317 -0.045595 -0.010246 -0.030636 -0.023607   \n",
       "3  0.023898  ... -0.032067  0.013064 -0.036885 -0.004430 -0.022011 -0.014765   \n",
       "4  0.047492  ... -0.036413  0.025165 -0.063565  0.029113 -0.045179 -0.027492   \n",
       "5  0.026695  ... -0.031783  0.011810 -0.052689 -0.017665 -0.020827 -0.023144   \n",
       "\n",
       "       1020      1021      1022      1023  \n",
       "1 -0.013751 -0.040431  0.045520 -0.037951  \n",
       "2 -0.031996 -0.086167  0.071279 -0.000200  \n",
       "3 -0.031623 -0.052872  0.041466 -0.026117  \n",
       "4 -0.020567 -0.053423  0.059044  0.000596  \n",
       "5 -0.007389 -0.059902  0.054974 -0.015622  \n",
       "\n",
       "[5 rows x 1032 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract embedding results for second subset\n",
    "embeddings2 = output2.embeddings\n",
    "embeddings2_np = embeddings2.detach().cpu().numpy()\n",
    " \n",
    "# convert to dataframe \n",
    "embeddings2_df = pd.DataFrame(embeddings2_np)\n",
    "\n",
    "# combine with columns up to 'bmi' from the original dataset \n",
    "df_subset2 = df.iloc[3500:].reset_index(drop=True)\n",
    "embeddings2_df = pd.concat([pd.DataFrame(embeddings2_np), df_subset2.loc[:, :'bmi']], axis=1)\n",
    "\n",
    "# reorder columns \n",
    "original2_cols = df_subset2.loc[:, :'bmi'].columns.tolist()\n",
    "embeddings2_cols = list(range(embeddings2_np.shape[1])) \n",
    "embeddings2_df = embeddings2_df[original2_cols + embeddings2_cols]\n",
    "\n",
    "embeddings2_df.index = range(1, len(embeddings2_df) + 1)\n",
    "\n",
    "embeddings2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dadc895c-ffaf-47bb-8ae9-fc6c81a15f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save embeddings2\n",
    "embeddings2_df.to_csv(\"./data/embeddings_moment_subset2_1024.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0df76c99-a836-4ff1-b61b-9d5a2ffbf0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqn</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>education</th>\n",
       "      <th>married</th>\n",
       "      <th>pir</th>\n",
       "      <th>bmi</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31183</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.055011</td>\n",
       "      <td>0.039953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044968</td>\n",
       "      <td>0.041012</td>\n",
       "      <td>-0.004977</td>\n",
       "      <td>0.017510</td>\n",
       "      <td>-0.047604</td>\n",
       "      <td>-0.740984</td>\n",
       "      <td>-0.065554</td>\n",
       "      <td>-0.168065</td>\n",
       "      <td>-0.018086</td>\n",
       "      <td>-0.036968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31186</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.035945</td>\n",
       "      <td>0.019263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024751</td>\n",
       "      <td>0.019362</td>\n",
       "      <td>-0.038653</td>\n",
       "      <td>0.010897</td>\n",
       "      <td>-0.060261</td>\n",
       "      <td>-0.859908</td>\n",
       "      <td>-0.084964</td>\n",
       "      <td>-0.084851</td>\n",
       "      <td>0.004536</td>\n",
       "      <td>-0.048224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31187</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4.29</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.024960</td>\n",
       "      <td>0.023898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.028877</td>\n",
       "      <td>-0.019058</td>\n",
       "      <td>-0.022575</td>\n",
       "      <td>-0.050082</td>\n",
       "      <td>-0.916767</td>\n",
       "      <td>-0.077313</td>\n",
       "      <td>-0.148370</td>\n",
       "      <td>-0.013513</td>\n",
       "      <td>-0.022824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31194</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.039385</td>\n",
       "      <td>0.047492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019135</td>\n",
       "      <td>0.017536</td>\n",
       "      <td>-0.026117</td>\n",
       "      <td>0.025634</td>\n",
       "      <td>-0.048371</td>\n",
       "      <td>-0.864587</td>\n",
       "      <td>-0.067891</td>\n",
       "      <td>-0.099167</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>-0.037764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31195</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.046546</td>\n",
       "      <td>0.026695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013865</td>\n",
       "      <td>-0.003344</td>\n",
       "      <td>0.024455</td>\n",
       "      <td>0.035110</td>\n",
       "      <td>-0.054572</td>\n",
       "      <td>-0.821886</td>\n",
       "      <td>-0.078766</td>\n",
       "      <td>-0.111349</td>\n",
       "      <td>0.016212</td>\n",
       "      <td>-0.050051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    seqn  gender  age  race  education  married   pir  bmi         0  \\\n",
       "1  31183       2   33     3          5        1  3.90    1 -0.055011   \n",
       "2  31186       2   46     1          1        3  1.68    1 -0.035945   \n",
       "3  31187       2   22     3          4        6  4.29    1 -0.024960   \n",
       "4  31194       2   47     1          1        3  1.02    1 -0.039385   \n",
       "5  31195       1   73     3          4        1  5.00    0 -0.046546   \n",
       "\n",
       "          1  ...        40        41        42        43        44        45  \\\n",
       "1  0.039953  ...  0.044968  0.041012 -0.004977  0.017510 -0.047604 -0.740984   \n",
       "2  0.019263  ...  0.024751  0.019362 -0.038653  0.010897 -0.060261 -0.859908   \n",
       "3  0.023898  ...  0.003397  0.028877 -0.019058 -0.022575 -0.050082 -0.916767   \n",
       "4  0.047492  ... -0.019135  0.017536 -0.026117  0.025634 -0.048371 -0.864587   \n",
       "5  0.026695  ...  0.013865 -0.003344  0.024455  0.035110 -0.054572 -0.821886   \n",
       "\n",
       "         46        47        48        49  \n",
       "1 -0.065554 -0.168065 -0.018086 -0.036968  \n",
       "2 -0.084964 -0.084851  0.004536 -0.048224  \n",
       "3 -0.077313 -0.148370 -0.013513 -0.022824  \n",
       "4 -0.067891 -0.099167  0.001687 -0.037764  \n",
       "5 -0.078766 -0.111349  0.016212 -0.050051  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reducing dimension for subset2\n",
    "def reduce_dimension(embedding, dim=50):\n",
    "    return embedding[:, :dim]\n",
    "reduced_embeddings2_np = reduce_dimension(embeddings2_np)\n",
    "\n",
    "# convert to dataframe \n",
    "red_embeddings2_df = pd.DataFrame(reduced_embeddings2_np)\n",
    "red_embeddings2_df = pd.concat([pd.DataFrame(reduced_embeddings2_np), df_subset2.loc[:, :'bmi']], axis=1)\n",
    "\n",
    "original2_cols = df_subset2.loc[:, :'bmi'].columns.tolist()\n",
    "embedding2_cols = list(range(reduced_embeddings2_np.shape[1])) \n",
    "red_embeddings2_df = red_embeddings2_df[original2_cols + embedding2_cols]\n",
    "red_embeddings2_df.index = range(1, len(red_embeddings2_df) + 1)\n",
    "\n",
    "red_embeddings2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0368f3a4-1b4f-4db9-be52-f4b9db63ec40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a57e3f-cab9-41d5-a1e8-e1645370efdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4025713-c621-4b16-8bf0-a59ffa6bec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save embeddings with dimension reduction for subset 2\n",
    "red_embeddings2_df.to_csv(\"./data/embeddings_moment_subset2_50.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb8c15c-46f8-4462-bfd7-4f4110fccb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(30, 6), sharey=True)\n",
    "axs.flatten()\n",
    "for i, idx in enumerate(np.arange(0, n_samples+1, n_samples//4-1)):\n",
    "    axs[i].plot(y[idx].squeeze().numpy())\n",
    "    axs[i].set_xticks(\n",
    "        ticks=np.arange(0, seq_len+1, 128), \n",
    "        labels=np.arange(0, seq_len+1, 128), \n",
    "        fontdict={\"fontsize\" : 16}\n",
    "    )\n",
    "    axs[i].set_title(\n",
    "        \"Frequency: {:.2f}\".format(c[:, 0][idx].squeeze().numpy(), ),\n",
    "        fontsize=16\n",
    "    )\n",
    "axs[0].set_yticks(\n",
    "    ticks=np.arange(-1.5, 1.5, 0.5), \n",
    "    labels=np.arange(-1.5, 1.5, 0.5),\n",
    "    fontdict={\"fontsize\" : 16}\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2710b14-68b4-4645-9b66-ee550845c37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cpu\") # CUDA not available \n",
    "\n",
    "model.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(x_enc=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0d80d5-6b85-4509-9263-add2a0659ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "embeddings = outputs.embeddings.detach().cpu().numpy()\n",
    "\n",
    "# Perform PCA on the embeddings\n",
    "embeddings_manifold = PCA(n_components=2).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e900c-682f-4a50-8078-eb5319464f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(f\"$y = \\sin(2c \\pi x) + \\epsilon$\", fontsize=20)\n",
    "plt.scatter(\n",
    "    embeddings_manifold[:, 0], \n",
    "    embeddings_manifold[:, 1],\n",
    "    c=c[:, 0].squeeze().numpy(),\n",
    "    cmap='magma'\n",
    ")\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.colorbar(\n",
    "    boundaries=np.arange(\n",
    "    synthetic_dataset.freq_range[0],\n",
    "    synthetic_dataset.freq_range[1]+1, 1)\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
